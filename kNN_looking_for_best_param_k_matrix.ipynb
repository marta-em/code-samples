{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# matrix of best errors for differen k nearest neighbors\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import spatial\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import collections\n",
    "import itertools\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "from pylab import *\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import scipy \n",
    "from sklearn import metrics\n",
    "from datetime import timedelta\n",
    "\n",
    "    \n",
    "    \n",
    "# sliding window\n",
    "\n",
    "def GetShiftingWindows(thelist, size):\n",
    "    return [ thelist[x:x+size] for x in range( len(thelist) - size + 1 ) ]\n",
    "\n",
    "\n",
    "\n",
    "def CalcEuclDist(dfspeed, speed, index, time_horizon):\n",
    "    #####################\n",
    "    # speed = df.speed.values\n",
    "    # time_horizon = 24   length\n",
    "    # index of a the test series\n",
    "    #####################\n",
    "\n",
    "    \n",
    "    X_test = dfspeed.ix[index:index+time_horizon].values \n",
    "    #X_test = df.speed.iloc[index:index+time_horizon].values \n",
    "    X_train = GetShiftingWindows(speed, time_horizon)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_train = np.array(X_train)\n",
    "    \n",
    "    #m = KnnDtw(n_neighbors=no_neighbors)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    # remove the WHOLE [includinng subseries ] series from the training set\n",
    "    # chk indexes of similar series\n",
    "    for i in range(0, len(X_train)):   \n",
    "        dist  = scipy.spatial.distance.euclidean(X_train[i], X_test)\n",
    "        distances.append(dist)\n",
    "    \n",
    "    return distances \n",
    "\n",
    "\n",
    "\n",
    "#error definition\n",
    "def mean_absolute_percentage_error_value(y_true, y_pred):\n",
    "        to_mean = []\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            if true != 0:\n",
    "                to_mean.append(np.abs((true - pred) / true))\n",
    "        return np.mean(to_mean) * 100\n",
    "\n",
    "def mae( y_true, y_pred):\n",
    "        return metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def rmse( y_true, y_pred):\n",
    "        return np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "    \n",
    "data_resol = [ '15min']\n",
    "    \n",
    "# data_resol = ['1h', '30min', '15min']\n",
    "pred_horizons = [24, 24, 24]\n",
    "\n",
    "#len of df: 3153\n",
    "\n",
    "#indexes = np.arange(10, 2902, 166)\n",
    "\n",
    "\n",
    "# TODO remove April from the first list of indexes and fix others too\n",
    "# indexes for 1h, 30m, 15min\n",
    "\n",
    "indexes = np.arange(10, 11433, 120)\n",
    "\n",
    "\n",
    "# i1 = np.arange(10, 2902, 166)\n",
    "# i2 = np.arange(10, 5756, 122)\n",
    "# i3 = np.arange(10, 11433, 120)\n",
    "# indexes = [i1, i2, i3]\n",
    "\n",
    "# indexes = [ np.arange(10, 2902, 166),\n",
    "#         np.arange(10, 5756, 122), \n",
    "#          np.arange(10, 11433, 120)  ] \n",
    "\n",
    "# indexes = [[10,  176,  342,  508,  674,  840, 1006, 1172, 1338, 1504, 1670,  1836, 2002, 2168, 2334, 2500, 2666, 2832],\n",
    "           \n",
    "# [ 10,  132,  254,  376,  498,  620,  742,  864,  986, 1108, 1230,  1352, 1474, 1596, 1718, 1840, 1962, 2084, 2206, 2328, 2450, 2572,\n",
    "#        2694, 2816, 2938, 3060, 3182, 3304, 3426, 3548, 3670, 3792, 3914,      4036, 4158, 4280, 4402, 4524, 4646, 4768, 4890, 5012, 5134, 5256,\n",
    "#        5378, 5500, 5622, 5744], \n",
    "           \n",
    "# [ 10,   130,   250,   370,   490,   610,   730,   850,   970,     1090,  1210,  1330,  1450,  1570,  1690,  1810,  1930,  2050, \n",
    "#  2170,  2290,  2410,  2530,  2650,  2770,  2890,  3010,  3130,    3250,  3370,  3490,  3610,  3730,  3850,  3970,  4090,  4210,\n",
    "#         4330,  4450,  4570,  4690,  4810,  4930,  5050,  5170,  5290,     5410,  5530,  5650,  5770,  5890,  6010,  6130,  6250,\n",
    "#       6370, 6490,  6610,  6730,  6850,  6970,  7090,  7210,  7330,  7450,    7570,  7690,  7810,  7930,  8050,  8170,  8290,  \n",
    "#      8410,  8530, 8650,  8770,  8890,  9010,  9130,  9250,  9370,  9490,  9610,      9730,  9850,  9970, 10090, 10210, 10330, \n",
    "#      10450, 10570, 10690, 10810, 10930, 11050, 11170, 11290, 11410]]\n",
    "\n",
    "time_freq = [ '15m']\n",
    "\n",
    "#time_freq = ['h', '30m', '15m']\n",
    "no_neigbors = np.arange(1,31,1)\n",
    "\n",
    "\n",
    "for res, hor, idxs, tf in zip(data_resol, pred_horizons, indexes, time_freq): \n",
    "    print('************************** data resolution [{}] ******************************************'.format(res))\n",
    "    \n",
    "    df = pd.read_csv('D:\\data from MnM Samdal raw\\Samdal_power_{}_no_outliers.csv'.format(res), parse_dates=[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #df.precipitation = df.precipitation.fillna(value=0)\n",
    "    df.power = df.power.interpolate(method='linear', limit = 2 )\n",
    "    df.speed = df.speed.interpolate(method='linear', limit = 2 )\n",
    "\n",
    "    df = df.rename( columns={\"Unnamed: 0\": \"time\"})\n",
    "\n",
    "\n",
    "    # discard April\n",
    "    df = df.drop(df[df.time.dt.month==4].index)\n",
    "\n",
    "    df.time = pd.to_datetime(df.time, format='%Y%m%d %H:%M:%s')\n",
    "    df = df.set_index('time')\n",
    "\n",
    "    df = df.dropna(subset=['speed'])\n",
    "\n",
    "    max_power =np.max(df.power)\n",
    "    speed = df.speed.values\n",
    "\n",
    "\n",
    "\n",
    "    time_horizon_lengths = np.arange(1,hor+1,1)\n",
    "\n",
    "    no_neigbors = np.arange(1,31,1)\n",
    "\n",
    "    list_nMAE_for_horizon_mtrx =[]\n",
    "    list_nRMSE_for_horizon_mtrx = []\n",
    "\n",
    "\n",
    "    list_last_pred_values = []\n",
    "\n",
    "    for t in time_horizon_lengths:\n",
    "        print('time horizon [{}]: '.format(res), t, '\\n')\n",
    "\n",
    "        list_nMAE_for_horizon = []\n",
    "        list_nRMSE_for_horizon = [] \n",
    "\n",
    "\n",
    "                # read index values of top neighbors to find them in df\n",
    "                #top_neigh_indexes = sorted_neigh.iloc[1:k+1].index    # take starting from ix 1 becauxe ix 0 is the same series\n",
    "\n",
    "        for k in no_neigbors:\n",
    "            #print('no_neighbors= ', k , '\\n')\n",
    "\n",
    "            list_nMAE = []\n",
    "            list_nRMSE = []\n",
    "\n",
    "\n",
    "            for u in indexes:\n",
    "\n",
    "\n",
    "                distances = CalcEuclDist(df.speed, speed, u, t)\n",
    "\n",
    "\n",
    "                df = df[:len(distances)]\n",
    "                df['knnDTW_distances'] = distances\n",
    "\n",
    "                # TODO sort acc to two distances?\n",
    "                # no? use knnDTW_distances instead of euclidean ! ?\n",
    "\n",
    "                # TODO remove indexes close to the test series\n",
    "                sorted_neigh = df.sort(columns=['knnDTW_distances'], ascending=True)\n",
    "            #        print('sorted_neigh', sorted_neigh.ix[:, ['power', 'knnDTW_distances']].head(5))\n",
    "\n",
    "                ##########################\n",
    "\n",
    "                # k neighbors\n",
    "                top_neigh_indexes = sorted_neigh.iloc[:k+1].index    # +1 because the first one is true series\n",
    "                #top_neigh_indexes = sorted_neigh.iloc[:30].index    # +1 because the first one is true series\n",
    "\n",
    "            #        print('top_neigh_indexes', top_neigh_indexes)\n",
    "                # find 6h windows based on indexes\n",
    "\n",
    "                time_horizon = np.timedelta64((t.item()-1), tf) # subtract 1 because we start from i, so i+5=6\n",
    "\n",
    "                found_6h_series = []\n",
    "\n",
    "                for m in top_neigh_indexes:\n",
    "                #    power_series = df.ix[i:i+6,'power']\n",
    "                    power_series = df.ix[m:m+time_horizon,'power'].values\n",
    "                    found_6h_series.append(power_series)   # first index is the tested series [true values]\n",
    "\n",
    "                #print(df_powers, '\\n')    \n",
    "\n",
    "                df_powers = pd.DataFrame(data=found_6h_series) # rows are neigboring series, #calc avg for columns\n",
    "                #print(df_powers, '\\n')\n",
    "\n",
    "                true_power_values = df_powers.iloc[0,:]\n",
    "            #    print('tru', true_power_values, '\\n')\n",
    "\n",
    "                predicted_power = df_powers.iloc[1:,:].mean(axis=0)\n",
    "                #print('predict', predicted_power, '\\n')\n",
    "            #    print('predict ty', type(predicted_power), '\\n')\n",
    "\n",
    "                last_predicted_power = df_powers.iloc[1:,-1].mean(axis=0)\n",
    "                #print('last_predict', last_predicted_power, '\\n')\n",
    "\n",
    "\n",
    "            #         predicted_power = df_powers.iloc[1:,:]\n",
    "            #         print('predict', predicted_power, '\\n')\n",
    "\n",
    "            # TODO : deal with nans in true power series\n",
    "            # chk interpolation instead of ffill\n",
    "                            # protect agains NaN\n",
    "    #             if np.any(np.isnan(true_power_values))==True:\n",
    "    #                 true_power_values = true_power_values.fillna(method='ffill' )\n",
    "\n",
    "                #print('tru', true_power_values, '\\n')\n",
    "\n",
    "            ############################\n",
    "            # finding similar speeds\n",
    "\n",
    "                found_speed_series = []\n",
    "\n",
    "                for m in top_neigh_indexes:\n",
    "                #    power_series = df.ix[i:i+6,'power']\n",
    "                    speed_series = df.ix[m:m+time_horizon,'speed'].values\n",
    "                    found_speed_series.append(speed_series)   # first index is the tested series [true values]\n",
    "\n",
    "                #print(df_powers, '\\n')    \n",
    "\n",
    "                df_speeds = pd.DataFrame(data=found_speed_series) # rows are neigboring series, #calc avg for columns\n",
    "                #print(df_powers, '\\n')\n",
    "\n",
    "                true_speed_values = df_speeds.iloc[0,:]\n",
    "            #    print('tru', true_power_values, '\\n')\n",
    "\n",
    "                predicted_speed = df_speeds.iloc[1:,:].mean(axis=0)\n",
    "                #print('predict speed', predicted_speed, '\\n')\n",
    "            #    print('predict ty', type(predicted_power), '\\n')\n",
    "\n",
    "                last_predicted_speed = df_speeds.iloc[1:,-1].mean(axis=0)\n",
    "                #print('last_predict speed', last_predicted_speed, '\\n')\n",
    "\n",
    "\n",
    "            #         predicted_power = df_powers.iloc[1:,:]\n",
    "            #         print('predict', predicted_power, '\\n')\n",
    "\n",
    "            # TODO : deal with nans in true power series\n",
    "            # chk interpolation instead of ffill\n",
    "                            # protect agains NaN\n",
    "    #             if np.any(np.isnan(true_speed_values))==True:\n",
    "    #                 true_speed_values = true_speed_values.fillna(method='ffill' )\n",
    "\n",
    "                #print('tru speed', true_speed_values, '\\n')\n",
    "\n",
    "                if np.any(np.isnan(true_power_values))==True:\n",
    "                    break\n",
    "\n",
    "                if np.any(np.isnan(predicted_power))==True:\n",
    "                    break\n",
    "\n",
    "            ###########\n",
    "\n",
    "                MAE_1h = mae(true_power_values, predicted_power)    # it's already an avg because i took a mean of predicted power\n",
    "                RMSE_1h = rmse(true_power_values, predicted_power)\n",
    "            #        print('MAE_1h', MAE_1h, '\\n')\n",
    "\n",
    "\n",
    "                nMAE_1h = (MAE_1h/max_power)*100\n",
    "                nRMSE_1h = (RMSE_1h/max_power)*100\n",
    "            #        print('nMAE_1h', nMAE_1h, '\\n')\n",
    "\n",
    "                list_nMAE.append(nMAE_1h)\n",
    "\n",
    "            avg_nMAE = sum(list_nMAE)/(len(list_nMAE))\n",
    "            avg_nRMSE = sum(list_nRMSE)/(len(list_nRMSE))\n",
    "\n",
    "            #print('avg errors for ', k , ' neighbors: \\n' ,'avg_nMAE = ' , nMAE_1h )\n",
    "\n",
    "            list_nMAE_for_horizon.append(avg_nMAE)\n",
    "            list_nRMSE_for_horizon.append(avg_nRMSE)\n",
    "            \n",
    "            #print(len(list_nMAE_for_horizon))\n",
    "            \n",
    "#             # save results to columns\n",
    "#             csv_input = pd.read_csv('kNN_Euc_k_matrix.csv')\n",
    "#             csv_input['nMAE_{}_hor_{}'.format(res,t)] = list_nMAE_for_horizon\n",
    "#             csv_input['nRMSE_{}_hor_{}'.format(res,t)] = list_nRMSE_for_horizon\n",
    "\n",
    "#             csv_input.to_csv('kNN_Euc_k_matrix.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "        #print('list_nMAE_for_horizon ', t, 'list: ', list_nMAE_for_horizon)\n",
    "        list_last_pred_values.append(last_predicted_power)\n",
    "\n",
    "\n",
    "        list_nMAE_for_horizon_mtrx.append(list_nMAE_for_horizon)\n",
    "        list_nRMSE_for_horizon_mtrx.append(list_nRMSE_for_horizon)\n",
    "\n",
    "    # TODO take last values from the predicted series     \n",
    "    #print('predicted series', list_last_pred_values)\n",
    "\n",
    "\n",
    "    csv_input = pd.read_excel('kNN_Euc_k_matrix.xlsx')\n",
    "    csv_input['nMAE_{}_hor_{}'.format(res,t)] = list_nMAE_for_horizon_mtrx\n",
    "    csv_input['nRMSE_{}_hor_{}'.format(res,t)] = list_nRMSE_for_horizon_mtrx\n",
    "\n",
    "    csv_input.to_excel('kNN_Euc_k_matrix.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
